{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzY5NDgsYmn5"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgI97LJuZEZf"
      },
      "source": [
        "## Building a Decision Tree from Scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nX6s0Eo0ZH_3"
      },
      "source": [
        "### **Node Representation**\n",
        "\n",
        "- **Purpose**: Represents a node in the decision tree, which can either be a leaf or an internal node.\n",
        "- **Attributes**:\n",
        "  - `is_leaf` (bool): To determine if the node is a leaf node.\n",
        "  - `feature_index` (int): The feature index used to split.\n",
        "  - `threshold` (float): The threshold value used to split the data.\n",
        "  - `prediction` (int): The value of the prediction (if the node is a leaf).\n",
        "  - `left` (dict): Left child node.\n",
        "  - `right` (dict): Right child node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmxsBreMVrvw"
      },
      "outputs": [],
      "source": [
        "def create_node(\n",
        "    is_leaf: bool,\n",
        "    feature_index: int = -1,\n",
        "    threshold: float = -1,\n",
        "    prediction: float = None,\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Creates a decision tree node.\n",
        "\n",
        "    Args:\n",
        "        is_leaf (bool): Whether the node is a leaf node.\n",
        "        feature_index (int): The feature index used for splitting.\n",
        "        threshold (float): The threshold value for splitting.\n",
        "        prediction (float): The prediction value for leaf nodes.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary representing a decision tree node.\n",
        "    \"\"\"\n",
        "\n",
        "    node = {\n",
        "        \"is_leaf\": is_leaf,\n",
        "        \"feature_index\": feature_index,\n",
        "        \"threshold\": threshold,\n",
        "        \"prediction\": prediction,\n",
        "        \"left\": None, # set to none initially. can assign child nodes after init\n",
        "        \"right\": None\n",
        "    }\n",
        "    return node"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWwt1ez3ZJyh"
      },
      "source": [
        "### **Splitting Dataset**\n",
        "\n",
        "- **Purpose**: Split the dataset into left and right parts based on a given feature and threshold.\n",
        "  - Iterate through each instance in the dataset.\n",
        "  - Compare the value of the selected feature with the given threshold.\n",
        "  - Append the instance to either the left or right split based on whether the feature value is less than or equal to the threshold.\n",
        "  - Make sure both the features and labels are split according"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4J2x56ZVxyd"
      },
      "outputs": [],
      "source": [
        "def split_dataset(\n",
        "    df: pd.DataFrame, feature_index: str, threshold: float\n",
        ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Splits the dataset based on a feature and a threshold.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The dataset including features and labels.\n",
        "        feature_index (str): The feature to split on.\n",
        "        threshold (float): The threshold value to use for the split.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the left and right datasets.\n",
        "    \"\"\"\n",
        "\n",
        "    column_list  = df.columns.tolist()\n",
        "    column_index = column_list.index(feature_index)\n",
        "    left_split  = []\n",
        "    right_split = []\n",
        "    numpy_dataset = df.to_numpy() # converting df to a numpy array for efficiency\n",
        "\n",
        "    for instance in numpy_dataset:\n",
        "      if instance[column_index] <= threshold:\n",
        "        left_split.append(instance)\n",
        "      else:\n",
        "        right_split.append(instance)\n",
        "\n",
        "    left_split = pd.DataFrame(left_split, columns=column_list)\n",
        "    right_split = pd.DataFrame(right_split, columns=column_list)\n",
        "\n",
        "    return left_split, right_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iLawW9qZt0i"
      },
      "source": [
        "### **Checking Purity**\n",
        "\n",
        "- **Purpose**: Determine if all the labels are the same.\n",
        "  - If all labels are identical, the node should be considered pure, and it will become a leaf node.\n",
        "  - Check if all elements are the same.\n",
        "  - This function helps determine whether further splitting is necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzNmFLqpWCET"
      },
      "outputs": [],
      "source": [
        "def is_pure(labels: pd.Series) -> bool:\n",
        "    \"\"\"\n",
        "    Checks if all the labels are the same.\n",
        "\n",
        "    Args:\n",
        "        labels (pd.Series): The label values.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if all labels are the same, False otherwise.\n",
        "    \"\"\"\n",
        "\n",
        "    if labels.nunique() == 1:\n",
        "      return True\n",
        "    else:\n",
        "      return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdVhZnuqeA8d"
      },
      "source": [
        "### **Finding the Best Split**\n",
        "\n",
        "- **Purpose**: Find the best feature and threshold to split the dataset.\n",
        "  - Iterate through each feature and determine possible thresholds.\n",
        "  - Use entropy as the metric to evaluate the quality of the split.\n",
        "  - For each threshold, calculate the entropy of the resulting splits and choose the one with the lowest entropy.\n",
        "  - The best split will minimize the entropy, meaning the resulting splits are as pure as possible.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiS-ejjLeFfr"
      },
      "outputs": [],
      "source": [
        "def calculate_thresholds(column: np.array) -> list[float]:\n",
        "  thresholds = []\n",
        "  sorted_column = np.sort(column)\n",
        "  for i in range(len(sorted_column) - 1): # -1 because there are n-1 thresholds\n",
        "    thresholds.append((sorted_column[i] + sorted_column[i+1]) / 2)\n",
        "  return thresholds\n",
        "\n",
        "def find_best_split(\n",
        "    df: pd.DataFrame, features: list[str], label_column: str\n",
        ") -> tuple[str, float]:\n",
        "    \"\"\"\n",
        "    Finds the best feature and threshold to split the dataset by minimizing entropy.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The dataset including features and labels.\n",
        "        features (list[str]): The list of feature column names.\n",
        "        label_column (str): The label column name.\n",
        "\n",
        "    Returns:\n",
        "        tuple: The feature name and threshold value for the best split.\n",
        "    \"\"\"\n",
        "\n",
        "    best_entropy = float(\"inf\")\n",
        "    best_feature = \"\"\n",
        "    best_threshold = -1\n",
        "\n",
        "    # making each column a numpy array for efficiency\n",
        "    numpy_columns = []\n",
        "    for feature in features:\n",
        "      numpy_columns.append(df[feature].to_numpy())\n",
        "\n",
        "    for i in range(len(features)): # for every feature\n",
        "      possible_thresholds = calculate_thresholds(numpy_columns[i])\n",
        "      for threshold in possible_thresholds: # go over every threshold\n",
        "        left_split, right_split = split_dataset(df, features[i], threshold)\n",
        "        weighted_entropy = calculate_entropy(left_split, right_split)\n",
        "        if weighted_entropy < best_entropy: # pick the best threshold based on smallest entropy\n",
        "          best_entropy = weighted_entropy\n",
        "          best_feature = features[i]\n",
        "          best_threshold = threshold\n",
        "\n",
        "    return best_feature, best_threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kPYPXJsZzZS"
      },
      "source": [
        "### **Calculating Entropy**\n",
        "\n",
        "- **Purpose**: Calculate the entropy for a given split of labels.\n",
        "  - Entropy is a measure of impurity, where lower values indicate a purer split.\n",
        "  - For each subset of labels (left and right), calculate the proportion of each class.\n",
        "  - Use the formula for entropy\n",
        "  - The entropy for the split is the weighted average of the left and right entropies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmMedLosXAzy"
      },
      "outputs": [],
      "source": [
        "def calculate_entropy(left_labels: pd.Series, right_labels: pd.Series) -> float:\n",
        "    \"\"\"\n",
        "    Calculates the entropy for a split.\n",
        "\n",
        "    Args:\n",
        "        left_labels (pd.Series): The label values for the left split.\n",
        "        right_labels (pd.Series): The label values for the right split.\n",
        "\n",
        "    Returns:\n",
        "        float: The entropy value for the split.\n",
        "    \"\"\"\n",
        "    left_size = len(left_labels)\n",
        "    right_size = len(right_labels)\n",
        "    total_size = left_size + right_size\n",
        "\n",
        "    if total_size == 0:\n",
        "        return 0\n",
        "\n",
        "    def entropy(labels):\n",
        "      p = {}\n",
        "      labels = labels.to_numpy().flatten()\n",
        "      for label in labels:\n",
        "        if label in p:\n",
        "          p[label] += 1\n",
        "        else:\n",
        "          p[label] = 1\n",
        "      for key in p:\n",
        "        p[key] = p[key] / len(labels)\n",
        "\n",
        "      summation = 0\n",
        "      for prob in p.values():\n",
        "        pi_log_pi = prob * np.log2(prob)\n",
        "        summation += pi_log_pi\n",
        "      return -summation\n",
        "\n",
        "    # Calculate entropy for both left and right splits\n",
        "    entropy_left = entropy(left_labels)\n",
        "    entropy_right = entropy(right_labels)\n",
        "\n",
        "    # Weighted average of both entropies\n",
        "    weighted_average = (left_size / total_size) * entropy_left + (right_size / total_size) * entropy_right\n",
        "    return weighted_average"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjpKjWbqgiU2"
      },
      "source": [
        "### **Calculating Prediction**\n",
        "\n",
        "- **Purpose**: Calculate the prediction value for a leaf node (most common label).\n",
        "- **Description**:\n",
        "  - This function returns the most common label in the dataset, which is used as the prediction for a leaf node.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmthfOXMggx6"
      },
      "outputs": [],
      "source": [
        "def calculate_prediction(labels: pd.Series) -> int:\n",
        "    \"\"\"\n",
        "    Calculates the prediction value for a leaf node.\n",
        "\n",
        "    Args:\n",
        "        labels (pd.Series): The label values.\n",
        "\n",
        "    Returns:\n",
        "        int: The most common value of the labels.\n",
        "    \"\"\"\n",
        "\n",
        "    return labels.value_counts().index[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ipjqbv6OaGiw"
      },
      "source": [
        "### **Building the Decision Tree**\n",
        "\n",
        "- **Purpose**: Recursively build the decision tree by finding the best split and creating nodes.\n",
        "- **Steps**:\n",
        "  - Start with the current depth as 0 and increase it with each recursive call.\n",
        "  - Stop the recursion if the current depth reaches the maximum depth or if the node is pure.\n",
        "  - Use the `find_best_split` function to determine the best feature and threshold for splitting.\n",
        "  - Create left and right child nodes recursively and attach them to the current node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBbCBDttWEfV"
      },
      "outputs": [],
      "source": [
        "def build_tree(\n",
        "    df: pd.DataFrame,\n",
        "    features: list[str],\n",
        "    label_column: str,\n",
        "    current_depth: int,\n",
        "    max_depth: int,\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Builds the decision tree recursively.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The dataset including features and labels.\n",
        "        features (list[str]): The list of feature column names.\n",
        "        label_column (str): The label column name.\n",
        "        current_depth (int): The current depth of the tree.\n",
        "        max_depth (int): The maximum allowed depth of the tree.\n",
        "\n",
        "    Returns:\n",
        "        dict: The root node of the decision tree.\n",
        "    \"\"\"\n",
        "    # base case\n",
        "    if current_depth >= max_depth or is_pure(df[label_column]):\n",
        "      return create_node(\n",
        "          is_leaf = True,\n",
        "          prediction = calculate_prediction(df[label_column])\n",
        "      )\n",
        "\n",
        "    # find best feature\n",
        "    best_feature, best_threshold = find_best_split(df, features, label_column)\n",
        "    node = create_node(\n",
        "        is_leaf = False,\n",
        "        feature_index = features.index(best_feature),\n",
        "        threshold = best_threshold\n",
        "    )\n",
        "\n",
        "    # split the data\n",
        "    left_split, right_split = split_dataset(df, best_feature, best_threshold)\n",
        "    node[\"left\"] = build_tree(left_split, features, label_column, current_depth+1, max_depth)\n",
        "    node[\"right\"] = build_tree(right_split, features, label_column, current_depth+1, max_depth)\n",
        "\n",
        "    return node"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTc14KM3Z9d-"
      },
      "source": [
        "### **Predicting Using the Tree**\n",
        "\n",
        "- **Purpose**: Predict the label for a given feature vector using the trained decision tree.\n",
        "- **Steps**:\n",
        "  - Start at the root of the tree and traverse down to a leaf node.\n",
        "  - For each internal node, decide whether to move left or right based on the feature value and threshold.\n",
        "  - When a leaf node is reached, return its prediction value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKB37Y4yYYg7"
      },
      "outputs": [],
      "source": [
        "def predict(tree: dict, sample: pd.Series) -> int:\n",
        "    \"\"\"\n",
        "    Predicts the label for a given feature vector using the decision tree.\n",
        "\n",
        "    Args:\n",
        "        tree (dict): The root node of the decision tree.\n",
        "        sample (pd.Series): The feature vector.\n",
        "\n",
        "    Returns:\n",
        "        int: The predicted label.\n",
        "    \"\"\"\n",
        "\n",
        "    if tree[\"is_leaf\"] == True:\n",
        "      return tree[\"prediction\"]\n",
        "\n",
        "    elif sample[tree[\"feature_index\"]] <= tree[\"threshold\"]:\n",
        "      return predict(tree[\"left\"], sample)\n",
        "\n",
        "    else:\n",
        "      return predict(tree[\"right\"], sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Iv-KI50a6GJ"
      },
      "source": [
        "### Using a Real-World Dataset and Comparison with Scikit-Learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETeO8A8iXPAR"
      },
      "outputs": [],
      "source": [
        "# Load the Iris dataset\n",
        "iris = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\", header=None)\n",
        "iris.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neBVD1-SgG_n"
      },
      "outputs": [],
      "source": [
        "# Prepare features and labels\n",
        "features = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
        "label_column = 'class'\n",
        "iris['class'] = iris['class'].apply(lambda x: 0 if x == 'Iris-setosa' else (1 if x == 'Iris-versicolor' else 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blmX6OqiXL_U"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into training and testing\n",
        "X_train, X_test = train_test_split(iris, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvLtKsgwXNiu"
      },
      "outputs": [],
      "source": [
        "max_depth = 3\n",
        "decision_tree = build_tree(X_train, features, label_column, 0, max_depth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ya0vV8bVgwyb",
        "outputId": "3c4ac822-3072-4b5e-8660-fbd8c95d24e6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-44-a74a2bfe260b>:16: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  elif sample[tree[\"feature_index\"]] <= tree[\"threshold\"]:\n"
          ]
        }
      ],
      "source": [
        "predictions = X_test.apply(lambda row: predict(decision_tree, row), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TO5Rlqcgytr",
        "outputId": "b44b5bb0-e4f8-464e-d323-219e3ffaecc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Custom Decision Tree Accuracy: 0.90\n"
          ]
        }
      ],
      "source": [
        "custom_accuracy = accuracy_score(X_test[label_column], predictions)\n",
        "print(f\"Custom Decision Tree Accuracy: {custom_accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebSrnFBQXe_f",
        "outputId": "e4efaa2c-9750-4782-c5fd-1f878bcbd7f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scikit-Learn Decision Tree Accuracy: 1.00\n"
          ]
        }
      ],
      "source": [
        "clf = DecisionTreeClassifier(max_depth=max_depth, random_state=42)\n",
        "clf.fit(X_train[features], X_train[label_column])\n",
        "sklearn_predictions = clf.predict(X_test[features])\n",
        "sklearn_accuracy = accuracy_score(X_test[label_column], sklearn_predictions)\n",
        "print(f\"Scikit-Learn Decision Tree Accuracy: {sklearn_accuracy:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
